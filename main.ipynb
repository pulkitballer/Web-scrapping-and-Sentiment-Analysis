{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5510d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel('Input-1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1fccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7278087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "url=data['URL'].tolist()\n",
    "url_id=data['URL_ID'].tolist()\n",
    "for i in url_id[:5]:\n",
    "    print(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b021c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"49aa2b13dcffd782c5a1cdfea7791b03\")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "driver=webdriver.Chrome()\n",
    "driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e74ce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Example Domain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example Domain\n",
      "This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n",
      "More information...\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://www.example.com'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "text = soup.get_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fafcae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel('Output Data Structure - Copy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "010ee81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d97d5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "text = open('54.txt', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "id": "3aa890b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "id": "67462856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 1452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_sentiment(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    if scores['compound'] > 0.5:\n",
    "        return 'Positive'\n",
    "    elif scores['compound'] < -0.5:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "classify_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "id": "7f9c2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = set()\n",
    "negative_words = set()\n",
    "\n",
    "for word in wordnet.words():\n",
    "    if classify_sentiment(word) == 'Positive':\n",
    "        positive_words.add(word)\n",
    "    elif classify_sentiment(word) == 'Negative':\n",
    "        negative_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "id": "8617fe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "positive_count = 0\n",
    "negative_count = 0\n",
    "\n",
    "for word in nltk.word_tokenize(text):\n",
    "    if word in positive_words:\n",
    "        positive_count += 1\n",
    "    elif word in negative_words:\n",
    "        negative_count += 1\n",
    "\n",
    "if positive_count > negative_count:\n",
    "    print('Positive')\n",
    "else:\n",
    "    print('Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "id": "e2de2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(tokens, positive_dict, negative_dict):\n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "    for token in tokens:\n",
    "        if token in positive_dict:\n",
    "            positive_score += 1\n",
    "    for token in tokens:\n",
    "        if token in negative_dict:\n",
    "            negative_score += 1\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(tokens) + 0.000001)\n",
    "\n",
    "    return positive_score, negative_score, polarity_score, subjectivity_score\n",
    "positive_dict = positive_words\n",
    "negative_dict = negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "id": "d8e4c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive score: 2\n",
      "Negative score: 2\n",
      "Polarity score: 0.0\n",
      "Subjectivity score: 0.0034482758590963134\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "positive_score, negative_score, polarity_score, subjectivity_score = calculate_scores(tokens, positive_dict, negative_dict)\n",
    "\n",
    "print(f\"Positive score: {positive_score}\")\n",
    "print(f\"Negative score: {negative_score}\")\n",
    "print(f\"Polarity score: {polarity_score}\")\n",
    "print(f\"Subjectivity score: {subjectivity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "id": "4b54e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_readability(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    average_sentence_length = len(words) / len(sentences)\n",
    "    num_complex_words = 0\n",
    "    for word in words:\n",
    "        if len(word) > 3:\n",
    "            num_complex_words += 1\n",
    "    percentage_complex_words = num_complex_words / len(words)\n",
    "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
    "\n",
    "    return average_sentence_length,percentage_complex_words,fog_index,num_complex_words\n",
    "average_sentence_length,percentage_complex_words,fog_index,num_complex_words = calculate_readability(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "id": "e8883d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_words_per_sentence(text):\n",
    "    sentences = text.split('. ')\n",
    "    total_words = 0\n",
    "    num_sentences = len(sentences)\n",
    "    for sentence in sentences:\n",
    "        num_words = len(sentence.split())\n",
    "        total_words += num_words\n",
    "        avg_words = total_words / num_sentences\n",
    "\n",
    "    return avg_words\n",
    "avg_word = avg_words_per_sentence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "id": "6e1bb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    punctuations = string.punctuation\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words and token not in punctuations]\n",
    "    return len(filtered_tokens)\n",
    "word_count = filter_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "id": "37db1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(text):\n",
    "    words = text.split()\n",
    "    syllable_counts = []\n",
    "    for word in words:\n",
    "        word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        num_vowels = 0\n",
    "        for letter in word:\n",
    "            if letter in \"aeiouAEIOU\":\n",
    "                num_vowels += 1\n",
    "        if word[-2:] in [\"es\", \"ed\"]:\n",
    "            num_vowels -= 1\n",
    "        syllable_counts.append(num_vowels)\n",
    "    return (syllable_counts)\n",
    "syllables_count = count_syllables(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "id": "7201c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_personal_pronouns(text):\n",
    "    pattern = re.compile(r'\\b(I|we|my|ours|us)\\b', re.I)\n",
    "    pronoun_list = pattern.findall(text)\n",
    "    return len(pronoun_list)\n",
    "\n",
    "personal_pronoun = count_personal_pronouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "id": "ef314c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.152462121212121\n"
     ]
    }
   ],
   "source": [
    "def avg_word_length(text):\n",
    "    words = text.split()\n",
    "    total_chars = 0\n",
    "    num_words = len(words)\n",
    "    for word in words:\n",
    "        num_chars = len(word)\n",
    "        total_chars += num_chars\n",
    "        avg_length = total_chars / num_words\n",
    "\n",
    "    return avg_length\n",
    "\n",
    "avg = avg_word_length(text)\n",
    "print(avg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "id": "c83438ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL_ID                                                                               \n",
       "URL                                                                                  \n",
       "POSITIVE SCORE                                                                    2.0\n",
       "NEGATIVE SCORE                                                                    2.0\n",
       "POLARITY SCORE                                                                    0.0\n",
       "SUBJECTIVITY SCORE                                                           0.003448\n",
       "AVG SENTENCE LENGTH                                                         17.575758\n",
       "PERCENTAGE OF COMPLEX WORDS                                                  0.560345\n",
       "FOG INDEX                                                                    7.254441\n",
       "AVG NUMBER OF WORDS PER SENTENCE                                            18.526316\n",
       "COMPLEX WORD COUNT                                                              650.0\n",
       "WORD COUNT                                                                      603.0\n",
       "SYLLABLE PER WORD                   [2, 1, 5, 1, 1, 2, 1, 4, 0, 3, 3, 2, 1, 2, 1, ...\n",
       "PERSONAL PRONOUNS                                                                 8.0\n",
       "AVG WORD LENGTH                                                              5.152462\n",
       "Name: 113, dtype: object"
      ]
     },
     "execution_count": 1463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[113] = ['','',positive_score, negative_score, polarity_score, subjectivity_score,average_sentence_length,percentage_complex_words,fog_index,avg_word,num_complex_words,word_count,syllables_count,personal_pronoun,avg]\n",
    "data.loc[113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "id": "fce33da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>26.246753</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>10.743135</td>\n",
       "      <td>33.943396</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>[2, 1, 4, 1, 3, 3, 3, 0, 3, 7, 1, 2, 1, 2, 0, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.803224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>20.419753</td>\n",
       "      <td>0.516324</td>\n",
       "      <td>8.374431</td>\n",
       "      <td>24.517241</td>\n",
       "      <td>854.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>[1, 1, 1, 4, 1, 2, 2, 1, 3, 0, 3, 4, 1, 1, 5, ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>22.441860</td>\n",
       "      <td>0.574093</td>\n",
       "      <td>9.206381</td>\n",
       "      <td>26.338462</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>[1, 1, 1, 2, 2, 1, 2, 1, 1, 3, 0, 3, 7, 2, 1, ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.537967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>19.229167</td>\n",
       "      <td>0.546046</td>\n",
       "      <td>7.910085</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>[1, 3, 3, 1, 2, 1, 1, 3, 1, 1, 0, 3, 4, 1, 2, ...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.919976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>24.912500</td>\n",
       "      <td>0.562970</td>\n",
       "      <td>10.190188</td>\n",
       "      <td>27.359375</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>[1, 2, 3, 1, 1, 1, 1, 1, 0, 3, 5, 5, 1, 1, 1, ...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.241005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>20.775510</td>\n",
       "      <td>0.564833</td>\n",
       "      <td>8.536137</td>\n",
       "      <td>22.390244</td>\n",
       "      <td>575.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>[3, 1, 2, 0, 3, 6, 1, 1, 4, 4, 1, 1, 1, 5, 1, ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.507625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>25.840580</td>\n",
       "      <td>0.553001</td>\n",
       "      <td>10.557432</td>\n",
       "      <td>41.184211</td>\n",
       "      <td>986.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>[1, 3, 1, 3, 0, 3, 3, 1, 1, 3, 1, 3, 1, 1, 4, ...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.286262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>19.742424</td>\n",
       "      <td>0.545664</td>\n",
       "      <td>8.115235</td>\n",
       "      <td>21.943396</td>\n",
       "      <td>711.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>[1, 2, 3, 1, 4, 0, 3, 5, 1, 4, 4, 1, 1, 3, 1, ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.232158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>26.766667</td>\n",
       "      <td>0.607721</td>\n",
       "      <td>10.949755</td>\n",
       "      <td>40.388889</td>\n",
       "      <td>488.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>[3, 3, 1, 1, 4, 2, 0, 3, 5, 1, 1, 4, 4, 2, 1, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.806052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>17.575758</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>7.254441</td>\n",
       "      <td>18.526316</td>\n",
       "      <td>650.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>[2, 1, 5, 1, 1, 2, 1, 4, 0, 3, 3, 2, 1, 2, 1, ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.152462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID URL  POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  \\\n",
       "0                          7.0             7.0        0.000000   \n",
       "1                          5.0             5.0        0.000000   \n",
       "2                          3.0             5.0       -0.250000   \n",
       "3                          6.0             5.0        0.090909   \n",
       "4                          7.0             3.0        0.400000   \n",
       "..     ...  ..             ...             ...             ...   \n",
       "109                        1.0             1.0        0.000000   \n",
       "110                        3.0             1.0        0.500000   \n",
       "111                        0.0             8.0       -1.000000   \n",
       "112                        4.0             0.0        1.000000   \n",
       "113                        2.0             2.0        0.000000   \n",
       "\n",
       "     SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  \\\n",
       "0              0.006927            26.246753                     0.611084   \n",
       "1              0.006046            20.419753                     0.516324   \n",
       "2              0.004145            22.441860                     0.574093   \n",
       "3              0.005959            19.229167                     0.546046   \n",
       "4              0.005018            24.912500                     0.562970   \n",
       "..                  ...                  ...                          ...   \n",
       "109            0.001965            20.775510                     0.564833   \n",
       "110            0.002243            25.840580                     0.553001   \n",
       "111            0.006140            19.742424                     0.545664   \n",
       "112            0.004981            26.766667                     0.607721   \n",
       "113            0.003448            17.575758                     0.560345   \n",
       "\n",
       "     FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  \\\n",
       "0    10.743135                         33.943396              1235.0   \n",
       "1     8.374431                         24.517241               854.0   \n",
       "2     9.206381                         26.338462              1108.0   \n",
       "3     7.910085                         25.181818              1008.0   \n",
       "4    10.190188                         27.359375              1122.0   \n",
       "..         ...                               ...                 ...   \n",
       "109   8.536137                         22.390244               575.0   \n",
       "110  10.557432                         41.184211               986.0   \n",
       "111   8.115235                         21.943396               711.0   \n",
       "112  10.949755                         40.388889               488.0   \n",
       "113   7.254441                         18.526316               650.0   \n",
       "\n",
       "     WORD COUNT                                  SYLLABLE PER WORD  \\\n",
       "0        1167.0  [2, 1, 4, 1, 3, 3, 3, 0, 3, 7, 1, 2, 1, 2, 0, ...   \n",
       "1         780.0  [1, 1, 1, 4, 1, 2, 2, 1, 3, 0, 3, 4, 1, 1, 5, ...   \n",
       "2        1017.0  [1, 1, 1, 2, 2, 1, 2, 1, 1, 3, 0, 3, 7, 2, 1, ...   \n",
       "3         925.0  [1, 3, 3, 1, 2, 1, 1, 3, 1, 1, 0, 3, 4, 1, 2, ...   \n",
       "4        1026.0  [1, 2, 3, 1, 1, 1, 1, 1, 0, 3, 5, 5, 1, 1, 1, ...   \n",
       "..          ...                                                ...   \n",
       "109       552.0  [3, 1, 2, 0, 3, 6, 1, 1, 4, 4, 1, 1, 1, 5, 1, ...   \n",
       "110       982.0  [1, 3, 1, 3, 0, 3, 3, 1, 1, 3, 1, 3, 1, 1, 4, ...   \n",
       "111       704.0  [1, 2, 3, 1, 4, 0, 3, 5, 1, 4, 4, 1, 1, 3, 1, ...   \n",
       "112       440.0  [3, 3, 1, 1, 4, 2, 0, 3, 5, 1, 1, 4, 4, 2, 1, ...   \n",
       "113       603.0  [2, 1, 5, 1, 1, 2, 1, 4, 0, 3, 3, 2, 1, 2, 1, ...   \n",
       "\n",
       "     PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                  1.0         5.803224  \n",
       "1                  7.0         5.010549  \n",
       "2                  3.0         5.537967  \n",
       "3                 18.0         4.919976  \n",
       "4                 18.0         5.241005  \n",
       "..                 ...              ...  \n",
       "109                9.0         5.507625  \n",
       "110               18.0         5.286262  \n",
       "111                2.0         5.232158  \n",
       "112                0.0         5.806052  \n",
       "113                8.0         5.152462  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 1465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "id": "1c124034",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('file2.xlsx', sheet_name='Sheet2', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e078624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
